{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# =================== CHANNEL ATTENTION ===================\n",
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    RCAN-style Channel Attention (as in IRE paper)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, num_channels // reduction_ratio, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(num_channels // reduction_ratio, num_channels, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.fc(self.avg_pool(x))\n",
    "        return x * w\n",
    "\n",
    "# =================== IMPROVED DENSE BLOCK ===================\n",
    "class ImprovedDenseBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    IRE Dense Block:\n",
    "    - 3 conv layers with dense connections\n",
    "    - Channel Attention\n",
    "    - Residual scaling = 0.2\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features=64, growth_channels=32):\n",
    "        super(ImprovedDenseBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_features, growth_channels, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv2 = nn.Conv2d(num_features + growth_channels, growth_channels, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv3 = nn.Conv2d(num_features + 2 * growth_channels, num_features, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "\n",
    "        self.ca = ChannelAttention(num_features)\n",
    "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.res_scale = 0.2  # residual scaling as in IRE paper\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.lrelu(self.conv1(x))\n",
    "        x2 = self.lrelu(self.conv2(torch.cat([x, x1], dim=1)))\n",
    "        x3 = self.conv3(torch.cat([x, x1, x2], dim=1))\n",
    "        x3 = self.ca(x3)\n",
    "        return x + x3 * self.res_scale\n",
    "\n",
    "# =================== RRDB BLOCK ===================\n",
    "class RRDB_IRE(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual-in-Residual Dense Block using 3 Improved Dense Blocks\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features=64, growth_channels=32):\n",
    "        super(RRDB_IRE, self).__init__()\n",
    "        self.db1 = ImprovedDenseBlock(num_features, growth_channels)\n",
    "        self.db2 = ImprovedDenseBlock(num_features, growth_channels)\n",
    "        self.db3 = ImprovedDenseBlock(num_features, growth_channels)\n",
    "        self.res_scale = 0.2  # residual-in-residual scaling\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.db1(x)\n",
    "        out = self.db2(out)\n",
    "        out = self.db3(out)\n",
    "        return x + out * self.res_scale\n",
    "\n",
    "# =================== IRE GENERATOR ===================\n",
    "class IREGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    IRE Generator for paired LR-HR datasets\n",
    "    No downsampling inside, uses RRDB backbone and upsampling for SR\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels=3,\n",
    "                 out_channels=3,\n",
    "                 num_features=64,\n",
    "                 num_rrdb_blocks=23,\n",
    "                 growth_channels=32,\n",
    "                 scale_factor=4):\n",
    "        super(IREGenerator, self).__init__()\n",
    "\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "        # Feature extraction\n",
    "        self.conv_first = nn.Conv2d(in_channels, num_features, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "\n",
    "        # RRDB trunk\n",
    "        self.rrdb_trunk = nn.Sequential(\n",
    "            *[RRDB_IRE(num_features, growth_channels) for _ in range(num_rrdb_blocks)]\n",
    "        )\n",
    "        self.trunk_conv = nn.Conv2d(num_features, num_features, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "\n",
    "        # Upsampling layers (nearest + conv)\n",
    "        self.upconv1 = nn.Conv2d(num_features, num_features, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.upconv2 = nn.Conv2d(num_features, num_features, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "\n",
    "        # High-resolution reconstruction\n",
    "        self.hr_conv = nn.Conv2d(num_features, num_features, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv_last = nn.Conv2d(num_features, out_channels, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fea = self.conv_first(x)\n",
    "        trunk = self.trunk_conv(self.rrdb_trunk(fea))\n",
    "        fea = fea + trunk\n",
    "\n",
    "        # Upsampling\n",
    "        fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
    "        fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
    "\n",
    "        out = self.conv_last(self.lrelu(self.hr_conv(fea)))\n",
    "        return out\n",
    "\n",
    "# =================== PAIRED LR-HR DATASET ===================\n",
    "class PairedSRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for paired LR-HR images.\n",
    "    Assumes LR and HR images already exist and filenames match.\n",
    "    \"\"\"\n",
    "    def __init__(self, lr_dir, hr_dir):\n",
    "        self.lr_paths = sorted([\n",
    "            os.path.join(lr_dir, f)\n",
    "            for f in os.listdir(lr_dir)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ])\n",
    "        self.hr_paths = sorted([\n",
    "            os.path.join(hr_dir, f)\n",
    "            for f in os.listdir(hr_dir)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ])\n",
    "\n",
    "        assert len(self.lr_paths) == len(self.hr_paths), \"LR and HR images count mismatch!\"\n",
    "\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr = Image.open(self.lr_paths[idx]).convert(\"RGB\")\n",
    "        hr = Image.open(self.hr_paths[idx]).convert(\"RGB\")\n",
    "        lr = self.transform(lr)\n",
    "        hr = self.transform(hr)\n",
    "        return lr, hr\n",
    "\n",
    "# =================== QUICK TEST ===================\n",
    "if __name__ == \"__main__\":\n",
    "    model = IREGenerator(\n",
    "        in_channels=3,\n",
    "        out_channels=3,\n",
    "        num_features=64,\n",
    "        num_rrdb_blocks=3,  # reduced for quick test\n",
    "        growth_channels=32\n",
    "    )\n",
    "\n",
    "    # Test forward pass\n",
    "    x = torch.randn(1, 3, 64, 64)\n",
    "    y = model(x)\n",
    "    print(\"Generator output shape:\", y.shape)  # Expected: [1, 3, 256, 256]\n",
    "\n",
    "    # Test dataset\n",
    "    dataset = PairedSRDataset(\"data/LR\", \"data/HR\")\n",
    "    lr, hr = dataset[0]\n",
    "    print(\"LR shape:\", lr.shape, \"HR shape:\", hr.shape)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
